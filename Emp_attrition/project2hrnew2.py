# -*- coding: utf-8 -*-
"""project2HRnew2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n8EV98lY869R7lzkEPklbN1INVETaPky

#Import Libraries
"""

import seaborn as sns
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier
from sklearn.ensemble import HistGradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score,
                             classification_report, confusion_matrix, roc_auc_score, roc_curve)
from sklearn.preprocessing import label_binarize
from imblearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.preprocessing import StandardScaler
from tqdm import tqdm
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

"""#Read Data

"""

df = pd.read_csv('/content/Emp_attrition_csv.csv')

df.head()

df.shape

df.hist(bins=20, figsize=(25,30))
plt.show()

df.info()

df.describe()

cols_nulls=list(df.isnull().mean().sort_values(ascending=False).head(6).index)

for col in cols_nulls:
  print(f"### {col} ###")
  print(df[df[col].isna()]['Attrition'].value_counts())
  print('--'*15)

"""



#Data Preprocessing
"""

df.isnull().sum().sort_values(ascending = False).head(10)

df.drop_duplicates(inplace=True)
df.shape

df.drop(['Employee ID'],axis=1,inplace=True)

df['Attrition'] = df['Attrition'].map({'Stayed': 0, 'Left': 1})

df['Distance from Home'].fillna(df['Distance from Home'].mean(), inplace=True)
df['Company Tenure (In Months)'].fillna(df['Company Tenure (In Months)'].mean(), inplace=True)

label_encoders = {}
for col in df.select_dtypes(include='object').columns:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col])
    label_encoders[col] = le

df.head()

df.isnull().sum().sort_values(ascending = False).head(10)

"""#EDA"""

df.columns

sns.countplot(x = 'Gender',hue='Attrition' ,data=df)

sns.countplot(x = 'Marital Status',hue='Attrition' ,data=df)

sns.countplot(x = 'Job Role',hue='Attrition' ,data=df)

sns.countplot(x = 'Overtime',hue='Attrition' ,data=df)

#Stayed vs Left
sns.countplot(data=df, x='Attrition')
plt.title("Employee Attrition Distribution")
plt.xticks([0, 1], ['Stayed', 'Left'])
plt.xlabel("Attrition Status")
plt.ylabel("Number of Employees")
plt.show()

# Attrition Rate by Gender
attrition_by_gender = pd.crosstab(df['Gender'], df['Attrition'], normalize='index') * 100
attrition_by_gender.plot(kind='bar', stacked=True, colormap='Set2')
plt.title("Attrition Rate by Gender")
plt.ylabel("Percentage (%)")
plt.xlabel("Gender")
plt.legend(["Stayed", "Left"])
plt.show()

#Age Distribution by Attrition
sns.boxplot(x='Attrition', y='Age', data=df)
plt.title("Age Distribution by Attrition Status")
plt.xticks([0, 1], ['Stayed', 'Left'])
plt.xlabel("Attrition Status")
plt.ylabel("Age")
plt.show()

#Tenure in Company vs Attrition
sns.violinplot(x='Attrition', y='Company Tenure (In Months)', data=df)
plt.title("Company Tenure vs Attrition")
plt.xticks([0, 1], ['Stayed', 'Left'])
plt.xlabel("Attrition Status")
plt.ylabel("Tenure (Months)")
plt.show()

#Attrition Count by Job Role
sns.countplot(data=df, x='Job Role', hue='Attrition')
plt.title("Attrition Count by Job Role")
plt.xlabel("Job Role")
plt.ylabel("Number of Employees")
plt.legend(["Stayed", "Left"])
plt.xticks(rotation=45)
plt.show()

df.columns

""" # Spliting"""

X = df.drop('Attrition', axis=1)
y = df['Attrition']

# X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

X_train, y_test = SMOTE(random_state=42).fit_resample(X_train, y_train)

print(f"X_train shape: {X_train.shape}")
print(f"y_train shape: {y_train.shape}")
print(f"X_test shape: {X_test.shape}")
print(f"y_test shape: {y_test.shape}")

"""#Models

"""

models = {
    'RandomForestClassifier': RandomForestClassifier(),
    'LogisticRegression': LogisticRegression(max_iter=200),
    "XGBoost": XGBClassifier(scale_pos_weight=(y_train.value_counts()[0] / y_train.value_counts()[1]),
                              use_label_encoder=False, eval_metric='logloss', random_state=42),
    # 'SVM Classifier': SVC(),
    'KNN Classifier': KNeighborsClassifier(),
    'Decision Tree Classifier': DecisionTreeClassifier(),
    'Decision Tree Regressor': DecisionTreeRegressor(),
    # 'Random Forest Regressor': RandomForestRegressor(class_weight='balanced', random_state=42)
}

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from tqdm import tqdm

def ml_model(x_train, y_train, x_test, y_test, models):
    models_loss = dict()

    for model_name, model in tqdm(models.items()):
        model.fit(x_train, y_train)

        y_pred_train = model.predict(x_train)
        y_pred_test = model.predict(x_test)

        models_loss[model_name] = [
            round(accuracy_score(y_train, y_pred_train) * 100, 2),
            round(accuracy_score(y_test, y_pred_test) * 100, 2),
            round(precision_score(y_train, y_pred_train, average='binary', zero_division=0) * 100, 2),
            round(precision_score(y_test, y_pred_test, average='binary', zero_division=0) * 100, 2),
            round(recall_score(y_train, y_pred_train, average='binary', zero_division=0) * 100, 2),
            round(recall_score(y_test, y_pred_test, average='binary', zero_division=0) * 100, 2),
            round(f1_score(y_train, y_pred_train, average='binary', zero_division=0) * 100, 2),
            round(f1_score(y_test, y_pred_test, average='binary', zero_division=0) * 100, 2),
        ]

    return models_loss

models_loss = ml_model(X_train,y_train,X_test,y_test,models)
acc_df = pd.DataFrame(models_loss,index=['accuracy_trian','accuracy_test','precision_train','precision_test','recall_train','recall_test','f1_train','f1_test'])
acc_df.T

"""#Model Evaluation

"""

models_loss = ml_model(X_train, y_train, X_test, y_test, models)

# تحويل النتائج إلى DataFrame
metrics = ['accuracy_train', 'accuracy_test',
           'precision_train', 'precision_test',
           'recall_train', 'recall_test',
           'f1_train', 'f1_test']

results_df = pd.DataFrame(models_loss, index=metrics).T
results_df

plt.figure(figsize=(10,6))
results_df[['accuracy_train', 'accuracy_test']].plot(kind='bar')
plt.title("Model Accuracy Comparison")
plt.ylabel("Accuracy (%)")
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.tight_layout()
plt.show()

plt.figure(figsize=(10,6))
results_df[['f1_train', 'f1_test']].plot(kind='bar', color=['lightgreen', 'salmon'])
plt.title("Model F1-Score Comparison")
plt.ylabel("F1-Score (%)")
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.tight_layout()
plt.show()

plt.figure(figsize=(10,6))
results_df[['precision_test', 'recall_test']].plot(kind='bar', color=['skyblue', 'orange'])
plt.title("Model Precision and Recall (Test Data)")
plt.ylabel("Score (%)")
plt.xticks(rotation=45)
plt.grid(axis='y')
plt.tight_layout()
plt.show()

