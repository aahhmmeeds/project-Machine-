# -*- coding: utf-8 -*-
"""project1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UGgqtI7x0-pfvw5gBbsYBcVhz8wl6JrE
"""

# Import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Models from scikit-learn
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier
from sklearn.ensemble import HistGradientBoostingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split
from sklearn.preprocessing import StandardScaler
# Evaluation metrics
from sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score,
                             classification_report, confusion_matrix, roc_auc_score, roc_curve)
from sklearn.preprocessing import label_binarize
# SMOTE and Pipeline to avoid data leakage during cross-validation
from imblearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE

# Additional models: XGBoost, LightGBM, CatBoost
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.preprocessing import StandardScaler
from tqdm import tqdm

df=pd.read_csv('/content/Churn_Modelling.csv')

df.shape

df.head()

df.hist(bins=20, figsize=(20,30))
plt.show()

df.info()

df.isnull().sum().sort_values(ascending = False).head(10)

df.duplicated().sum()

df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1, inplace=True)

df_encoded = df.copy()

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
for col in ['Gender', 'Geography']:
    df_encoded[col] = LabelEncoder().fit_transform(df_encoded[col])

df_encoded.head()

df_encoded.info()

import matplotlib.pyplot as plt
corr_matrix = df_encoded.corr()
plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix')
plt.show()

numerical_features = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']
for feature in numerical_features:
    plt.figure(figsize=(8, 6))
    sns.histplot(df_encoded[feature], kde=True)
    plt.title(f'Distribution of {feature}')
    plt.xlabel(feature)
    plt.ylabel('Frequency')
    plt.show()

categorical_features = ['Geography', 'Gender', 'HasCrCard', 'IsActiveMember']
for feature in categorical_features:
    plt.figure(figsize=(8, 6))
    sns.countplot(x=feature, hue='Exited', data=df_encoded)
    plt.title(f'Count of {feature} by Exited Status')
    plt.xlabel(feature)
    plt.ylabel('Count')
    plt.show()

plt.figure(figsize=(8, 6))
sns.boxplot(x='Exited', y='Balance', data=df_encoded)
plt.title('Balance vs. Exited Status')
plt.xlabel('Exited')
plt.ylabel('Balance')
plt.show()

plt.figure(figsize=(8, 6))
sns.boxplot(x='Exited', y='CreditScore', data=df_encoded)
plt.title('CreditScore vs. Exited Status')
plt.xlabel('Exited')
plt.ylabel('CreditScore')
plt.show()

plt.figure(figsize=(8, 6))
sns.boxplot(x='Exited', y='Age', data=df_encoded)
plt.title('Age vs. Exited Status')
plt.xlabel('Exited')
plt.ylabel('Age')
plt.show()

X = df_encoded.drop('Exited', axis=1)
y = df_encoded['Exited']

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

models = {
        'Logistic Regression':LogisticRegression(),
        'svm':SVC(),
        'knn':KNeighborsClassifier(),
        'DT':DecisionTreeClassifier(),
        'RF':RandomForestClassifier()}

def ml_model(x_train,y_train,x_test,y_test,models):
  models_loss=dict()
  for model_name, model in tqdm(models.items()):
      model.fit(x_train,y_train)
      y_pred_train = model.predict(x_train)
      y_pred_test = model.predict(x_test)
      models_loss[model_name] = [round(accuracy_score(y_train,y_pred_train)*100,2),
                                round(accuracy_score(y_test,y_pred_test)*100,2),
                                round(precision_score(y_train,y_pred_train,average='micro')*100,2),
                                round(precision_score(y_test,y_pred_test,average='micro')*100,2),
                                round(recall_score(y_train,y_pred_train,average='micro')*100,2),
                                round(recall_score(y_test,y_pred_test,average='micro')*100,2),
                                round(f1_score(y_train,y_pred_train,average='micro')*100,2),
                                round(f1_score(y_test,y_pred_test,average='micro')*100,2)
                                ]
  return models_loss

models_loss = ml_model(X_train,y_train,X_test,y_test,models)
acc_df = pd.DataFrame(models_loss,index=['accuracy_trian','accuracy_test','precision_train','precision_test','recall_train','recall_test','f1_train','f1_test'])
acc_df.T